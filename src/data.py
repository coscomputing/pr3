"""
Dataset loading and preprocessing for Phase Retrieval.

Supports:
- MNIST
- CelebA
- EMDB-1050 (cryo-EM projections)

Implements data augmentation as specified in paper Table 1 (Appendix A):
- Random horizontal flips (CelebA/EMDB only)  
- Random rotations ±5° (CelebA/EMDB only)
"""

import torch
from torch.utils.data import Dataset, DataLoader
import torchvision
import torchvision.transforms as transforms
import torchvision.transforms.functional as TF
import numpy as np
import h5py
from pathlib import Path
from typing import Optional


class PhaseRetrievalDataset(Dataset):
    def __init__(self, root, dataset_name='MNIST', split='train', download=False, 
                 augment=False):
        """
        Generic dataset wrapper for Phase Retrieval.
        
        Args:
            root: Root directory for datasets
            dataset_name: 'MNIST', 'CelebA', or 'EMDB-1050'
            split: 'train' or 'test'
            download: Whether to download dataset if not present
            augment: Whether to apply data augmentation (horizontal flip, rotation)
        
        Returns:
            x: Ground truth image [1, H, W] (real)
            (Measurements b are computed on-the-fly during training)
        """
        self.dataset_name = dataset_name
        self.split = split
        self.augment = augment and (split == 'train')  # Only augment training data
        self.root = Path(root)

        # Resize to 32 for MNIST to allow 5 pooling layers (32->16->8->4->2->1)
        size = 32 if dataset_name=='MNIST' else 64
        
        # Base transform (no augmentation here, done in __getitem__)
        transform = transforms.Compose([
            transforms.Resize(size),
            transforms.CenterCrop(size),
            transforms.ToTensor(),
        ])

        if dataset_name == 'MNIST':
            try:
                self.data = torchvision.datasets.MNIST(
                    root=str(self.root),
                    train=(split=='train'),
                    transform=transform,
                    download=download
                )
            except (RuntimeError, OSError) as e:
                print(f"MNIST download failed: {e}. Using Fake Data.")
                self.data = FakeData(32, 100)
                
        elif dataset_name == 'CelebA':
            try:
                self.data = torchvision.datasets.CelebA(
                    root=str(self.root),
                    split=split,
                    target_type='attr',
                    transform=transforms.Compose([
                        transforms.CenterCrop(178), # CelebA standard crop
                        transforms.Resize(64),
                        transforms.Grayscale(),
                        transforms.ToTensor()
                    ]),
                    download=download
                )
            except (RuntimeError, OSError) as e:
                print(f"CelebA not found: {e}. Using Fake Data.")
                self.data = FakeData(64, 100)
                
        elif dataset_name == 'EMDB-1050':
            # Load from HDF5 file generated by generate_emdb_dataset.py
            emdb_path = self.root / 'EMDB-1050' / 'projections.h5'
            
            if not emdb_path.exists():
                print(f"EMDB-1050 not found at {emdb_path}")
                print("Please run: python src/generate_emdb_dataset.py")
                print("Using Fake Data for now.")
                self.data = FakeData(64, 100)
                self.is_emdb = False
            else:
                self.emdb_file = h5py.File(str(emdb_path), 'r')
                self.data_subset = 'train' if split == 'train' else 'test'
                self.data = self.emdb_file[self.data_subset]['images']
                self.is_emdb = True
                print(f"Loaded EMDB-1050 {split} set: {len(self.data)} projections")
        else:
            raise ValueError(f"Unknown dataset {dataset_name}")

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        """
        Get a single sample.
        
        Returns:
            x: Ground truth image tensor [1, H, W] (float32)
        """
        # Load data based on dataset type
        if self.dataset_name == 'EMDB-1050' and hasattr(self, 'is_emdb') and self.is_emdb:
            # Load from HDF5
            x = torch.from_numpy(self.data[idx]).unsqueeze(0).float()  # [1, H, W]
        else:
            # Load from torchvision dataset
            x, _ = self.data[idx]  # x is already [1, H, W] from transforms
        
        # Apply data augmentation if enabled (CelebA/EMDB only, as per paper)
        if self.augment and self.dataset_name in ['CelebA', 'EMDB-1050']:
            # Random horizontal flip
            if torch.rand(1).item() > 0.5:
                x = TF.hflip(x)
            
            # Random rotation within ±5 degrees (as specified in paper Table 1)
            angle = (torch.rand(1).item() - 0.5) * 10.0  # [-5, 5] degrees
            x = TF.rotate(x, angle, interpolation=TF.InterpolationMode.BILINEAR)
        
        return x


class FakeData(Dataset):
    """Placeholder dataset for when real data is not available"""
    def __init__(self, size, length):
        self.size = size
        self.length = length
    
    def __len__(self):
        return self.length
    
    def __getitem__(self, idx):
        return torch.zeros((1, self.size, self.size), dtype=torch.float32), 0
